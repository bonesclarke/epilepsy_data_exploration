{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb920ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# MNE Libraries\n",
    "import mne\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "from mne.preprocessing import ICA, create_eog_epochs, create_ecg_epochs\n",
    "\n",
    "# Scipy libraries\n",
    "from scipy import signal\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the plot output path\n",
    "plot_output_path = Path('plot_outputs')\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "plot_output_path.mkdir(exist_ok=True)\n",
    "print(f\"Directory '{plot_output_path}' is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set montage\n",
    "standard_1020_montage = mne.channels.make_standard_montage('easycap-M1')\n",
    "standard_1020_montage.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d280a413",
   "metadata": {},
   "source": [
    "# Load Subject Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd02c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject Information\n",
    "subject_info = pd.read_csv('data/seina_scalp/subject_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f7dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory\n",
    "data_dir = Path('data')\n",
    "\n",
    "# Initialize lists to store data\n",
    "all_seizures = []\n",
    "all_patients = []\n",
    "\n",
    "# Load all JSON files from subdirectories\n",
    "json_files = sorted(list(data_dir.glob('**/*.json')))  # ** searches subdirectories, sorted for consistent order\n",
    "print(f\"Found {len(json_files)} JSON files\")\n",
    "print(\"Files found:\")\n",
    "for f in json_files:\n",
    "    print(f\"  - {f}\")\n",
    "print(\"\\nLoading data...\")\n",
    "\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract patient-level information\n",
    "        patient_info = {\n",
    "            'patient_id': data['patient_id'],\n",
    "            'sampling_rate_hz': data['sampling_rate_hz'],\n",
    "            'num_channels': len(data['channels']),\n",
    "            'json_file_path': str(json_file)  # Store the file path for reference\n",
    "        }\n",
    "        \n",
    "        # Check if there's a top-level file_name (like PN01)\n",
    "        if 'file_name' in data:\n",
    "            patient_info['file_name'] = data['file_name']\n",
    "            patient_info['registration_start_time'] = data.get('registration_start_time')\n",
    "            patient_info['registration_end_time'] = data.get('registration_end_time')\n",
    "        \n",
    "        # Store patient info\n",
    "        all_patients.append(patient_info)\n",
    "        \n",
    "        # Process each seizure\n",
    "        for seizure in data['seizures']:\n",
    "            seizure_record = {\n",
    "                'patient_id': data['patient_id'],\n",
    "                'sampling_rate_hz': data['sampling_rate_hz'],\n",
    "                'seizure_number': seizure['seizure_number']\n",
    "            }\n",
    "            \n",
    "            # Add all seizure fields dynamically to handle variations\n",
    "            for key, value in seizure.items():\n",
    "                seizure_record[key] = value\n",
    "            \n",
    "            # If file info is at patient level, add it to seizure record\n",
    "            if 'file_name' in patient_info and 'file_name' not in seizure:\n",
    "                seizure_record['file_name'] = patient_info['file_name']\n",
    "                if 'registration_start_time' in patient_info:\n",
    "                    seizure_record['registration_start_time'] = patient_info['registration_start_time']\n",
    "                    seizure_record['registration_end_time'] = patient_info['registration_end_time']\n",
    "            \n",
    "            all_seizures.append(seizure_record)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {json_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\nData loading complete!\")\n",
    "\n",
    "# Create DataFrames\n",
    "seizures_df = pd.DataFrame(all_seizures)\n",
    "patients_df = pd.DataFrame(all_patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e91f2f9",
   "metadata": {},
   "source": [
    "# Data Loading and Raw EDF Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94094f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Seina Scalp edf files\n",
    "def process_all_edf_files(data_dir='data/seina_scalp', output_dir='plot_outputs'):\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Process subjects PN00 through PN17\n",
    "    for subject_num in range(18):  # 0 to 17\n",
    "        subject = f'PN{subject_num:02d}'  # Format as PN00, PN01, etc.\n",
    "        subject_dir = Path(data_dir) / subject\n",
    "        \n",
    "        # Check if subject directory exists\n",
    "        if not subject_dir.exists():\n",
    "            print(f\"Directory {subject_dir} not found, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Find all .edf files in the subject directory\n",
    "        edf_files = list(subject_dir.glob('*.edf'))\n",
    "        \n",
    "        if not edf_files:\n",
    "            print(f\"No EDF files found in {subject_dir}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing subject {subject}...\")\n",
    "        print(f\"Found {len(edf_files)} EDF file(s)\")\n",
    "        \n",
    "        # Process each EDF file\n",
    "        for edf_file in edf_files:\n",
    "            try:\n",
    "                # Extract file number from filename (e.g., PN00-1.edf -> 1)\n",
    "                file_stem = edf_file.stem  # Gets filename without extension\n",
    "                file_num = file_stem.split('-')[-1] if '-' in file_stem else '1'\n",
    "                \n",
    "                print(f\"  Processing {edf_file.name}...\")\n",
    "                \n",
    "                # Load EDF file\n",
    "                raw = mne.io.read_raw_edf(str(edf_file), preload=True, verbose=False)\n",
    "                \n",
    "                # Get available channels\n",
    "                available_channels = raw.ch_names\n",
    "                \n",
    "                # Set channel types\n",
    "                raw.set_channel_types({'2':'ecg', '1':'ecg'})\n",
    "                \n",
    "                print(f\"    Successfully loaded {len(available_channels)} channels\")\n",
    "                \n",
    "                # Apply bandpass filter\n",
    "                raw.filter(0.1, 60, fir_design='firwin')\n",
    "                \n",
    "                # Plot the raw time series data\n",
    "                fig = raw.plot(show=False, scalings={'eeg': 140e-6})\n",
    "                output_filename = output_path / f'{subject}_raw_{file_num}_edf_plot.png'\n",
    "                fig.savefig(output_filename)\n",
    "                plt.close(fig)\n",
    "                print(f\"    Saved raw plot to {output_filename}\")\n",
    "                \n",
    "                # Plot Power Spectral Density (PSD)\n",
    "                try:\n",
    "                    fig_psd = raw.compute_psd(method='multitaper', fmin=0.1, fmax=60).plot(\n",
    "                        average=False,  # Show individual channels\n",
    "                        amplitude=True,  # Show in dB\n",
    "                        spatial_colors=True,  # Color by sensor location\n",
    "                        show=False\n",
    "                    )\n",
    "                    psd_filename = output_path / f'{subject}_raw_{file_num}_psd_plot.png'\n",
    "                    fig_psd.savefig(psd_filename)\n",
    "                    plt.close(fig_psd)\n",
    "                    print(f\"    Saved PSD plot to {psd_filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    Warning: Could not create PSD plot: {str(e)}\")\n",
    "                \n",
    "                try:\n",
    "                    fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "        \n",
    "                    # Compute PSD\n",
    "                    psd = raw.compute_psd(method='multitaper', fmin=0.1, fmax=60, verbose=False)\n",
    "                    \n",
    "                    # Get data and average across channels\n",
    "                    psds, freqs = psd.get_data(return_freqs=True)\n",
    "                    psd_mean = np.mean(psds, axis=0)\n",
    "                    psd_std = np.std(psds, axis=0)\n",
    "                    \n",
    "                    # Plot mean with std as shaded area\n",
    "                    ax.plot(freqs, 10 * np.log10(psd_mean), 'b-', linewidth=2, label='Mean PSD')\n",
    "                    ax.fill_between(freqs, \n",
    "                                10 * np.log10(psd_mean - psd_std), \n",
    "                                10 * np.log10(psd_mean + psd_std), \n",
    "                                alpha=0.3, label='±1 SD')\n",
    "                    \n",
    "                    # Add frequency band annotations\n",
    "                    ax.axvspan(8, 12, alpha=0.2, color='green', label='Alpha (8-12 Hz)')\n",
    "                    ax.axvspan(13, 30, alpha=0.2, color='orange', label='Beta (13-30 Hz)')\n",
    "                    ax.axvspan(4, 7, alpha=0.2, color='blue', label='Theta (4-7 Hz)')\n",
    "                    \n",
    "                    ax.set_xlabel('Frequency (Hz)')\n",
    "                    ax.set_ylabel('Power Spectral Density (dB)')\n",
    "                    ax.set_title(f'{subject} - Average PSD Across All Channels')\n",
    "                    ax.legend()\n",
    "                    ax.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    psd_filename = output_path / f'{subject}_raw_{file_num}_psd_averaged.png'\n",
    "                    plt.savefig(psd_filename, dpi=300, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    print(f\"    Saved averaged PSD plot to {psd_filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    Warning: Could not create PSD plot: {str(e)}\")\n",
    "                    \n",
    "                try:\n",
    "                    # Define channel groups (adjust based on your montage)\n",
    "                    channel_groups = {\n",
    "                        'Frontal': ['EEG Fp1', 'EEG Fp2', 'EEG F3', 'EEG F4', 'EEG F7', 'EEG F8', 'EEG Fz'],\n",
    "                        'Central': ['EEG C3', 'EEG C4', 'EEG Cz'],\n",
    "                        'Parietal': ['EEG P3', 'EEG P4', 'EEG Pz'],\n",
    "                        'Occipital': ['EEG O1', 'EEG O2'],\n",
    "                        'Temporal': ['EEG T3', 'EEG T4', 'EEG T5', 'EEG T6']\n",
    "                    }\n",
    "                    \n",
    "                    # Get available channels\n",
    "                    available_channels = raw.ch_names\n",
    "                    \n",
    "                    # Filter groups to only include available channels\n",
    "                    filtered_groups = {}\n",
    "                    for group, channels in channel_groups.items():\n",
    "                        available_in_group = [ch for ch in channels if ch in available_channels]\n",
    "                        if available_in_group:\n",
    "                            filtered_groups[group] = available_in_group\n",
    "                    \n",
    "                    fig, axes = plt.subplots(2, 3, figsize=(26, 12))\n",
    "                    axes = axes.flatten()\n",
    "                    \n",
    "                    psd = raw.compute_psd(method='multitaper', fmin=0.1, fmax=60, verbose=False)\n",
    "                    psds, freqs = psd.get_data(return_freqs=True)\n",
    "                    \n",
    "                    colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
    "                    \n",
    "                    for idx, (group_name, channels) in enumerate(filtered_groups.items()):\n",
    "                        if idx >= len(axes):\n",
    "                            break\n",
    "                            \n",
    "                        ax = axes[idx]\n",
    "                        \n",
    "                        # Get indices for this group\n",
    "                        ch_indices = [raw.ch_names.index(ch) for ch in channels if ch in raw.ch_names]\n",
    "                        \n",
    "                        if ch_indices:\n",
    "                            # Average PSD for this group\n",
    "                            group_psd = np.mean(psds[ch_indices, :], axis=0)\n",
    "                            group_std = np.std(psds[ch_indices, :], axis=0)\n",
    "                            \n",
    "                            ax.plot(freqs, 10 * np.log10(group_psd), \n",
    "                                color=colors[idx % len(colors)], linewidth=2)\n",
    "                            ax.fill_between(freqs, \n",
    "                                        10 * np.log10(group_psd - group_std), \n",
    "                                        10 * np.log10(group_psd + group_std), \n",
    "                                        alpha=0.3, color=colors[idx % len(colors)])\n",
    "                            \n",
    "                            ax.set_title(f'{group_name} ({len(channels)} channels)')\n",
    "                            ax.set_xlabel('Frequency (Hz)')\n",
    "                            ax.set_ylabel('PSD (dB)')\n",
    "                            ax.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    # Remove empty subplots\n",
    "                    for idx in range(len(filtered_groups), len(axes)):\n",
    "                        fig.delaxes(axes[idx])\n",
    "                    \n",
    "                    plt.suptitle(f'{subject} - PSD by Brain Regions')\n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    psd_filename = output_path / f'{subject}_raw_{file_num}_psd_by_regions.png'\n",
    "                    plt.savefig(psd_filename, dpi=300, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    print(f\"    Saved regional PSD plot to {psd_filename}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    Warning: Could not create regional PSD plot: {str(e)}\")\n",
    "                \n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Error processing {edf_file.name}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\nProcessing complete! All plots saved to {output_dir}/\")\n",
    "\n",
    "# Run the function\n",
    "process_all_edf_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc84cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Seina Scalp edf files\n",
    "def process_all_chb_edf_files(data_dir='data/chb-mit', output_dir='plot_outputs'):\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Process subjects\n",
    "    for subject_num in range(24):  # 1 to 24\n",
    "        subject = f'chb{subject_num:02d}'  # Format as PN00, PN01, etc.\n",
    "        subject_dir = Path(data_dir) / subject\n",
    "        \n",
    "        # Check if subject directory exists\n",
    "        if not subject_dir.exists():\n",
    "            print(f\"Directory {subject_dir} not found, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Find all .edf files in the subject directory\n",
    "        edf_files = list(subject_dir.glob('*.edf'))\n",
    "        \n",
    "        if not edf_files:\n",
    "            print(f\"No EDF files found in {subject_dir}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing subject {subject}...\")\n",
    "        print(f\"Found {len(edf_files)} EDF file(s)\")\n",
    "        \n",
    "        # Process each EDF file\n",
    "        for edf_file in edf_files:\n",
    "            try:\n",
    "                # Extract file number from filename (e.g., PN00-1.edf -> 1)\n",
    "                file_stem = edf_file.stem  # Gets filename without extension\n",
    "                file_num = file_stem.split('_')[-1] if '_' in file_stem else '1'\n",
    "                \n",
    "                print(f\"  Processing {edf_file.name}...\")\n",
    "                \n",
    "                # Load EDF file\n",
    "                raw = mne.io.read_raw_edf(str(edf_file), preload=True, verbose=False)\n",
    "                \n",
    "                # Get available channels\n",
    "                available_channels = raw.ch_names\n",
    "                \n",
    "                print(f\"    Successfully loaded {len(available_channels)} channels\")\n",
    "                \n",
    "                # Apply bandpass filter\n",
    "                raw.filter(0.2, 50, fir_design='firwin')\n",
    "                \n",
    "                # Plot the raw time series data\n",
    "                fig = raw.plot(show=False, scalings={'eeg': 200e-6})\n",
    "                output_filename = output_path / f'{subject}_raw_{file_num}_edf_plot.png'\n",
    "                fig.savefig(output_filename)\n",
    "                plt.close(fig)\n",
    "                print(f\"    Saved raw plot to {output_filename}\")\n",
    "                \n",
    "                # Plot Power Spectral Density (PSD)\n",
    "                try:\n",
    "                    fig_psd = raw.compute_psd(method='multitaper', fmin=0.2, fmax=50).plot(\n",
    "                        average=False,  # Show individual channels\n",
    "                        amplitude=True,  # Show in dB\n",
    "                        spatial_colors=True,  # Color by sensor location\n",
    "                        show=False\n",
    "                    )\n",
    "                    psd_filename = output_path / f'{subject}_raw_{file_num}_psd_plot.png'\n",
    "                    fig_psd.savefig(psd_filename)\n",
    "                    plt.close(fig_psd)\n",
    "                    print(f\"    Saved PSD plot to {psd_filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    Warning: Could not create PSD plot: {str(e)}\")\n",
    "                \n",
    "                try:\n",
    "                    fig, ax = plt.subplots(1, 1, figsize=(18, 10))\n",
    "        \n",
    "                    # Compute PSD\n",
    "                    psd = raw.compute_psd(method='multitaper', fmin=0.2, fmax=50, verbose=False)\n",
    "                    \n",
    "                    # Get data and average across channels\n",
    "                    psds, freqs = psd.get_data(return_freqs=True)\n",
    "                    psd_mean = np.mean(psds, axis=0)\n",
    "                    psd_std = np.std(psds, axis=0)\n",
    "                    \n",
    "                    # Plot mean with std as shaded area\n",
    "                    ax.plot(freqs, 10 * np.log10(psd_mean), 'b-', linewidth=2, label='Mean PSD')\n",
    "                    ax.fill_between(freqs, \n",
    "                                10 * np.log10(psd_mean - psd_std), \n",
    "                                10 * np.log10(psd_mean + psd_std), \n",
    "                                alpha=0.3, label='±1 SD')\n",
    "                    \n",
    "                    # Add frequency band annotations\n",
    "                    ax.axvspan(8, 12, alpha=0.2, color='green', label='Alpha (8-12 Hz)')\n",
    "                    ax.axvspan(13, 30, alpha=0.2, color='orange', label='Beta (13-30 Hz)')\n",
    "                    ax.axvspan(4, 7, alpha=0.2, color='blue', label='Theta (4-7 Hz)')\n",
    "                    \n",
    "                    ax.set_xlabel('Frequency (Hz)')\n",
    "                    ax.set_ylabel('Power Spectral Density (dB)')\n",
    "                    ax.set_title(f'{subject} - Average PSD Across All Channels')\n",
    "                    ax.legend()\n",
    "                    ax.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    psd_filename = output_path / f'{subject}_raw_{file_num}_psd_averaged.png'\n",
    "                    plt.savefig(psd_filename, dpi=300, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    print(f\"    Saved averaged PSD plot to {psd_filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"    Warning: Could not create PSD plot: {str(e)}\")\n",
    "                    \n",
    "                try:\n",
    "                    # Define channel groups (adjust based on your montage)\n",
    "                    channel_groups = {\n",
    "                        'Frontal': ['FP1-F7', 'FP1-F3', 'FP2-F4', 'FP2-F8'],\n",
    "                        'Central': ['F3-C3', 'C3-P3', 'F4-C4', 'C4-P4', 'FZ-CZ'],\n",
    "                        'Parietal': ['P3-O1', 'P4-O2', 'P8-O2', 'P7-T7'],\n",
    "                        'Temporal': ['F7-T7', 'F8-T8', 'T8-P8-0', 'TZ-FT9']\n",
    "                    }\n",
    "                    \n",
    "                    # Get available channels\n",
    "                    available_channels = raw.ch_names\n",
    "                    \n",
    "                    # Filter groups to only include available channels\n",
    "                    filtered_groups = {}\n",
    "                    for group, channels in channel_groups.items():\n",
    "                        available_in_group = [ch for ch in channels if ch in available_channels]\n",
    "                        if available_in_group:\n",
    "                            filtered_groups[group] = available_in_group\n",
    "                    \n",
    "                    fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "                    axes = axes.flatten()\n",
    "                    \n",
    "                    psd = raw.compute_psd(method='multitaper', fmin=0.2, fmax=50, verbose=False)\n",
    "                    psds, freqs = psd.get_data(return_freqs=True)\n",
    "                    \n",
    "                    colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
    "                    \n",
    "                    for idx, (group_name, channels) in enumerate(filtered_groups.items()):\n",
    "                        if idx >= len(axes):\n",
    "                            break\n",
    "                            \n",
    "                        ax = axes[idx]\n",
    "                        \n",
    "                        # Get indices for this group\n",
    "                        ch_indices = [raw.ch_names.index(ch) for ch in channels if ch in raw.ch_names]\n",
    "                        \n",
    "                        if ch_indices:\n",
    "                            # Average PSD for this group\n",
    "                            group_psd = np.mean(psds[ch_indices, :], axis=0)\n",
    "                            group_std = np.std(psds[ch_indices, :], axis=0)\n",
    "                            \n",
    "                            ax.plot(freqs, 10 * np.log10(group_psd), \n",
    "                                color=colors[idx % len(colors)], linewidth=2)\n",
    "                            ax.fill_between(freqs, \n",
    "                                        10 * np.log10(group_psd - group_std), \n",
    "                                        10 * np.log10(group_psd + group_std), \n",
    "                                        alpha=0.3, color=colors[idx % len(colors)])\n",
    "                            \n",
    "                            ax.set_title(f'{group_name} ({len(channels)} channels)')\n",
    "                            ax.set_xlabel('Frequency (Hz)')\n",
    "                            ax.set_ylabel('PSD (dB)')\n",
    "                            ax.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    # Remove empty subplots\n",
    "                    for idx in range(len(filtered_groups), len(axes)):\n",
    "                        fig.delaxes(axes[idx])\n",
    "                    \n",
    "                    plt.suptitle(f'{subject} - PSD by Brain Regions')\n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    psd_filename = output_path / f'{subject}_raw_{file_num}_psd_by_regions.png'\n",
    "                    plt.savefig(psd_filename, dpi=300, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "                    print(f\"    Saved regional PSD plot to {psd_filename}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    Warning: Could not create regional PSD plot: {str(e)}\")\n",
    "                \n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Error processing {edf_file.name}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"\\nProcessing complete! All plots saved to {output_dir}/\")\n",
    "\n",
    "# Run the function\n",
    "process_all_chb_edf_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b2018",
   "metadata": {},
   "source": [
    "# Calculate Propagation Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a01933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_channel_onsets(data, sfreq, threshold, window_size, \n",
    "                         seizure_start=None, seizure_end=None):\n",
    "    n_channels, n_samples = data.shape\n",
    "    window_samples = int(window_size * sfreq)\n",
    "    onset_times = {}\n",
    "    \n",
    "    for ch_idx in range(n_channels):\n",
    "        channel_data = data[ch_idx, :]\n",
    "        \n",
    "        # Calculate envelope using Hilbert transform\n",
    "        analytic_signal = signal.hilbert(channel_data)\n",
    "        envelope = np.abs(analytic_signal)\n",
    "        \n",
    "        # Smooth envelope\n",
    "        envelope_smooth = signal.savgol_filter(envelope, window_samples, 3)\n",
    "        \n",
    "        # Calculate baseline and threshold\n",
    "        if seizure_start is not None and seizure_start > 10:\n",
    "            # Use pre-seizure period as baseline\n",
    "            baseline_end = int((seizure_start - 1) * sfreq)\n",
    "            baseline = envelope_smooth[:baseline_end]\n",
    "        else:\n",
    "            # Use first 10 seconds as baseline\n",
    "            baseline = envelope_smooth[:int(10 * sfreq)]\n",
    "        \n",
    "        baseline_mean = np.mean(baseline)\n",
    "        baseline_std = np.std(baseline)\n",
    "        onset_threshold = baseline_mean + threshold * baseline_std\n",
    "        \n",
    "        # Find onset (first crossing of threshold)\n",
    "        if seizure_start is not None:\n",
    "            # Search around known seizure time\n",
    "            search_start = max(0, int((seizure_start - 5) * sfreq))\n",
    "            search_end = min(n_samples, int((seizure_start + 10) * sfreq))\n",
    "            search_region = envelope_smooth[search_start:search_end]\n",
    "            \n",
    "            crossings = np.where(search_region > onset_threshold)[0]\n",
    "            if len(crossings) > 0:\n",
    "                onset_sample = search_start + crossings[0]\n",
    "                onset_times[ch_idx] = onset_sample / sfreq\n",
    "        else:\n",
    "            # Search entire signal\n",
    "            crossings = np.where(envelope_smooth > onset_threshold)[0]\n",
    "            if len(crossings) > 0:\n",
    "                # Find sustained elevation (not just spikes)\n",
    "                for crossing in crossings:\n",
    "                    if crossing + window_samples < n_samples:\n",
    "                        if np.mean(envelope_smooth[crossing:crossing+window_samples]) > onset_threshold:\n",
    "                            onset_times[ch_idx] = crossing / sfreq\n",
    "                            break\n",
    "    \n",
    "    return onset_times\n",
    "\n",
    "\n",
    "def calculate_propagation_metrics(onset_times, ch_names, info):\n",
    "    speeds = []\n",
    "    delays = []\n",
    "    sequence = []\n",
    "    \n",
    "    # Sort channels by onset time\n",
    "    sorted_onsets = sorted(onset_times.items(), key=lambda x: x[1])\n",
    "    \n",
    "    # Get electrode positions (simplified - using standard positions)\n",
    "    positions = estimate_electrode_positions(ch_names, info)\n",
    "    \n",
    "    # Calculate propagation between consecutive onsets\n",
    "    for i in range(len(sorted_onsets) - 1):\n",
    "        ch1_idx, time1 = sorted_onsets[i]\n",
    "        ch2_idx, time2 = sorted_onsets[i + 1]\n",
    "        \n",
    "        # Time delay\n",
    "        delay = time2 - time1\n",
    "        delays.append(delay)\n",
    "        \n",
    "        # Spatial distance (in mm, estimated)\n",
    "        if ch1_idx in positions and ch2_idx in positions:\n",
    "            pos1 = positions[ch1_idx]\n",
    "            pos2 = positions[ch2_idx]\n",
    "            distance = euclidean(pos1, pos2) * 100  # Convert to mm\n",
    "            \n",
    "            # Calculate speed (mm/s)\n",
    "            if delay > 0:\n",
    "                speed = distance / delay\n",
    "                speeds.append(speed)\n",
    "        \n",
    "        sequence.append((ch_names[ch1_idx], ch_names[ch2_idx], delay))\n",
    "    \n",
    "    return speeds, delays, sequence\n",
    "\n",
    "\n",
    "def estimate_electrode_positions(ch_names, info):\n",
    "    # Standard 10-20 system approximate positions (normalized)\n",
    "    standard_positions = {\n",
    "        'Fp1': (-0.3, 0.9), 'Fp2': (0.3, 0.9),\n",
    "        'F3': (-0.5, 0.6), 'F4': (0.5, 0.6),\n",
    "        'F7': (-0.8, 0.5), 'F8': (0.8, 0.5),\n",
    "        'C3': (-0.5, 0), 'C4': (0.5, 0),\n",
    "        'T3': (-0.9, 0), 'T4': (0.9, 0),\n",
    "        'T5': (-0.8, -0.5), 'T6': (0.8, -0.5),\n",
    "        'P3': (-0.5, -0.6), 'P4': (0.5, -0.6),\n",
    "        'O1': (-0.3, -0.9), 'O2': (0.3, -0.9),\n",
    "        'Fz': (0, 0.7), 'Cz': (0, 0), 'Pz': (0, -0.7)\n",
    "    }\n",
    "    \n",
    "    positions = {}\n",
    "    for idx, ch_name in enumerate(ch_names):\n",
    "        # Try to match standard names\n",
    "        ch_clean = ch_name.upper().replace('-', '').replace('EEG', '').strip()\n",
    "        \n",
    "        for std_name, pos in standard_positions.items():\n",
    "            if std_name in ch_clean:\n",
    "                positions[idx] = pos\n",
    "                break\n",
    "        \n",
    "        # If no match, assign a default position\n",
    "        if idx not in positions:\n",
    "            # Distribute unknown channels in a circle\n",
    "            angle = 2 * np.pi * idx / len(ch_names)\n",
    "            positions[idx] = (np.cos(angle), np.sin(angle))\n",
    "    \n",
    "    return positions\n",
    "\n",
    "\n",
    "def calculate_spatial_gradient(onset_times, ch_names):\n",
    "    if len(onset_times) < 3:\n",
    "        return None\n",
    "    \n",
    "    # Convert to arrays for analysis\n",
    "    times = np.array(list(onset_times.values()))\n",
    "    \n",
    "    # Calculate gradient magnitude\n",
    "    gradient = np.gradient(times)\n",
    "    \n",
    "    return {\n",
    "        'mean_gradient': np.mean(np.abs(gradient)),\n",
    "        'max_gradient': np.max(np.abs(gradient)),\n",
    "        'gradient_variance': np.var(gradient)\n",
    "    }\n",
    "\n",
    "\n",
    "def classify_propagation_pattern(speeds, sequence):\n",
    "    if not speeds:\n",
    "        return 'No propagation detected'\n",
    "    \n",
    "    mean_speed = np.mean(speeds)\n",
    "    std_speed = np.std(speeds)\n",
    "    cv = std_speed / mean_speed if mean_speed > 0 else 0\n",
    "    \n",
    "    # Classification based on speed characteristics\n",
    "    if mean_speed < 10:  # mm/s\n",
    "        pattern = 'Slow propagation'\n",
    "    elif mean_speed < 50:\n",
    "        pattern = 'Moderate propagation'\n",
    "    else:\n",
    "        pattern = 'Fast propagation'\n",
    "    \n",
    "    # Add variability assessment\n",
    "    if cv < 0.3:\n",
    "        pattern += ' - Uniform'\n",
    "    elif cv < 0.6:\n",
    "        pattern += ' - Variable'\n",
    "    else:\n",
    "        pattern += ' - Highly variable'\n",
    "    \n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e154993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seizure_propagation_speeds(edf_path, \n",
    "                                      seizure_start_time=None, \n",
    "                                      seizure_end_time=None,\n",
    "                                      sampling_rate=256,\n",
    "                                      detection_threshold=3.0,\n",
    "                                      window_size=1.0,\n",
    "                                      min_seizure_duration=10):\n",
    "    # Load EDF file\n",
    "    try:\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading EDF file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Get data and channel info\n",
    "    data = raw.get_data()\n",
    "    ch_names = raw.ch_names\n",
    "    sfreq = raw.info['sfreq']\n",
    "    \n",
    "    # Apply basic preprocessing\n",
    "    # Bandpass filter for seizure frequencies (typically 3-30 Hz)\n",
    "    data_filtered = mne.filter.filter_data(data, sfreq, l_freq=3, h_freq=30)\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        'file_path': edf_path,\n",
    "        'num_channels': len(ch_names),\n",
    "        'sampling_rate': sfreq,\n",
    "        'propagation_speeds': [],\n",
    "        'onset_delays': [],\n",
    "        'onset_sequence': [],\n",
    "        'mean_propagation_speed': None,\n",
    "        'max_propagation_speed': None,\n",
    "        'seizure_detected': False\n",
    "    }\n",
    "    \n",
    "    # Detect seizure onset for each channel\n",
    "    onset_times = detect_channel_onsets(data_filtered, sfreq, \n",
    "                                       detection_threshold, \n",
    "                                       window_size,\n",
    "                                       seizure_start_time,\n",
    "                                       seizure_end_time)\n",
    "    \n",
    "    if len(onset_times) < 2:\n",
    "        print(\"Insufficient seizure onsets detected across channels\")\n",
    "        return results\n",
    "    \n",
    "    results['seizure_detected'] = True\n",
    "    \n",
    "    # Calculate propagation speeds\n",
    "    speeds, delays, sequence = calculate_propagation_metrics(\n",
    "        onset_times, ch_names, raw.info\n",
    "    )\n",
    "    \n",
    "    results['propagation_speeds'] = speeds\n",
    "    results['onset_delays'] = delays\n",
    "    results['onset_sequence'] = sequence\n",
    "    \n",
    "    if speeds:\n",
    "        results['mean_propagation_speed'] = np.mean(speeds)\n",
    "        results['max_propagation_speed'] = np.max(speeds)\n",
    "        results['median_propagation_speed'] = np.median(speeds)\n",
    "        results['std_propagation_speed'] = np.std(speeds)\n",
    "    \n",
    "    # Add additional metrics\n",
    "    results['spatial_gradient'] = calculate_spatial_gradient(onset_times, ch_names)\n",
    "    results['propagation_pattern'] = classify_propagation_pattern(speeds, sequence)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812929ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(edf_files, annotation_files=None, output_path='propagation_speeds.csv'):\n",
    "    all_results = []\n",
    "    \n",
    "    for i, edf_file in enumerate(edf_files):\n",
    "        print(f\"Processing file {i+1}/{len(edf_files)}: {edf_file}\")\n",
    "        \n",
    "        # Get seizure annotations if available\n",
    "        seizure_start = None\n",
    "        seizure_end = None\n",
    "        \n",
    "        if annotation_files and edf_file in annotation_files:\n",
    "            # Parse annotation file for seizure times\n",
    "            # This would depend on your annotation format\n",
    "            pass\n",
    "        \n",
    "        # Extract propagation speeds\n",
    "        results = extract_seizure_propagation_speeds(\n",
    "            edf_file, \n",
    "            seizure_start_time=seizure_start,\n",
    "            seizure_end_time=seizure_end\n",
    "        )\n",
    "        \n",
    "        if results and results['seizure_detected']:\n",
    "            # Flatten results for DataFrame\n",
    "            flat_results = {\n",
    "                'file': edf_file,\n",
    "                'mean_speed': results['mean_propagation_speed'],\n",
    "                'max_speed': results['max_propagation_speed'],\n",
    "                'median_speed': results.get('median_propagation_speed'),\n",
    "                'std_speed': results.get('std_propagation_speed'),\n",
    "                'num_channels': results['num_channels'],\n",
    "                'propagation_pattern': results['propagation_pattern'],\n",
    "                'num_propagation_events': len(results['propagation_speeds'])\n",
    "            }\n",
    "            \n",
    "            # Add spatial gradient metrics if available\n",
    "            if results['spatial_gradient']:\n",
    "                flat_results.update({\n",
    "                    'mean_gradient': results['spatial_gradient']['mean_gradient'],\n",
    "                    'gradient_variance': results['spatial_gradient']['gradient_variance']\n",
    "                })\n",
    "            \n",
    "            all_results.append(flat_results)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Dataset saved to {output_path}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n=== Dataset Summary ===\")\n",
    "    print(f\"Total files processed: {len(edf_files)}\")\n",
    "    print(f\"Files with detected seizures: {len(df)}\")\n",
    "    print(f\"\\nPropagation Speed Statistics:\")\n",
    "    print(f\"Mean speed across all seizures: {df['mean_speed'].mean():.2f} mm/s\")\n",
    "    print(f\"Median speed across all seizures: {df['median_speed'].median():.2f} mm/s\")\n",
    "    print(f\"Speed range: {df['mean_speed'].min():.2f} - {df['mean_speed'].max():.2f} mm/s\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_path = \"data/PN00/PN00-1.edf\"\n",
    "results = extract_seizure_propagation_speeds(edf_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
