{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9256d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data set\n",
    "processed_df = pl.read_parquet(\"processed_data/comprehensive_eeg_features.parquet\")\n",
    "\n",
    "print(f\"Shape: {processed_df.shape}\")\n",
    "print(f\"Columns: {processed_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_classification_data(df, target_column, feature_columns=None):\n",
    "    \"\"\"\n",
    "    Prepare data for classification by separating labeled and unlabeled data\n",
    "    \"\"\"\n",
    "    labeled_df = df.filter(pl.col(target_column) != \"\")\n",
    "    unlabeled_df = df.filter(pl.col(target_column) == \"\")\n",
    "    \n",
    "    if feature_columns is None:\n",
    "        exclude_cols = ['seizure_type', 'localization', 'lateralization', 'patient_id', 'seizure_id']\n",
    "        feature_columns = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    X_labeled = labeled_df.select(feature_columns).to_numpy()\n",
    "    y_labeled = labeled_df.select(target_column).to_numpy().ravel()\n",
    "    \n",
    "    X_unlabeled = unlabeled_df.select(feature_columns).to_numpy()\n",
    "    \n",
    "    return X_labeled, y_labeled, X_unlabeled, feature_columns, exclude_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_classifier(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train XGBoost classifier with proper label encoding\n",
    "    \"\"\"\n",
    "    # Fit encoder on ALL labels (train + test) to avoid unseen label errors\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_labels = np.concatenate([y_train, y_test])\n",
    "    label_encoder.fit(all_labels)\n",
    "    \n",
    "    # Transform train and test sets\n",
    "    y_train_encoded = label_encoder.transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "    \n",
    "    n_classes = len(label_encoder.classes_)\n",
    "    print(f\"Number of classes detected: {n_classes}\")\n",
    "    print(f\"Classes: {label_encoder.classes_}\")\n",
    "    \n",
    "    # Initialize and train model with explicit num_class\n",
    "    if n_classes == 2:\n",
    "        # Binary classification\n",
    "        model = xgb.XGBClassifier(\n",
    "            n_estimators=1000,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.01,\n",
    "            objective='binary:logistic',\n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        # Multi-class classification\n",
    "        model = xgb.XGBClassifier(\n",
    "            n_estimators=1000,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.01,\n",
    "            objective='multi:softprob',\n",
    "            num_class=n_classes,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    print(f'X train shape: {X_train.shape}')\n",
    "    print(f'Y train encoded shape: {y_train_encoded.shape}')\n",
    "    \n",
    "    model.fit(X_train, y_train_encoded)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return model, y_pred, y_test_encoded, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, label_encoder=None):\n",
    "    \"\"\"\n",
    "    Print evaluation metrics\n",
    "    \"\"\"\n",
    "    if label_encoder:\n",
    "        y_true_labels = label_encoder.inverse_transform(y_true)\n",
    "        y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_true_labels, y_pred_labels))\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confusion_matrix(y_true_labels, y_pred_labels))\n",
    "    else:\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(X, y, cv_folds=4):\n",
    "    \"\"\"\n",
    "    Perform cross-validation to assess model stability\n",
    "    \"\"\"\n",
    "    # Encode labels if they're strings\n",
    "    label_encoder = LabelEncoder()\n",
    "    if isinstance(y[0], str):\n",
    "        y_encoded = label_encoder.fit_transform(y)\n",
    "    else:\n",
    "        y_encoded = y\n",
    "        \n",
    "    n_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    if n_classes == 2:\n",
    "        # Binary classification\n",
    "        model = xgb.XGBClassifier(\n",
    "            n_estimators=1000,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.01,\n",
    "            objective='binary:logistic',\n",
    "            random_state=42\n",
    "        )\n",
    "    else:\n",
    "        # Multi-class classification\n",
    "        model = xgb.XGBClassifier(\n",
    "            n_estimators=1000,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.01,\n",
    "            objective='multi:softprob',\n",
    "            num_class=n_classes,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    scores = cross_val_score(model, X, y_encoded, cv=cv_folds, scoring='accuracy')\n",
    "    print(f\"Cross-validation scores: {scores}\")\n",
    "    print(f\"Mean accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bdfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_unlabeled_seizures(model, X_unlabeled, label_encoder=None):\n",
    "    \"\"\"\n",
    "    Predict labels for unlabeled seizures\n",
    "    \"\"\"\n",
    "    predictions = model.predict(X_unlabeled)\n",
    "    probabilities = model.predict_proba(X_unlabeled)\n",
    "    \n",
    "    if label_encoder:\n",
    "        predictions = label_encoder.inverse_transform(predictions)\n",
    "    \n",
    "    return predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d74912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, feature_names):\n",
    "    \"\"\"\n",
    "    Get and display feature importance\n",
    "    \"\"\"\n",
    "    importance = model.feature_importances_\n",
    "    feature_importance = list(zip(feature_names, importance))\n",
    "    feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    for feat, imp in feature_importance[:10]:\n",
    "        print(f\"{feat}: {imp:.4f}\")\n",
    "    \n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f69236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_seizure_classifier(df, target_column):\n",
    "    \"\"\"\n",
    "    Complete pipeline to build and evaluate a seizure classifier\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X_labeled, y_labeled, X_unlabeled, feature_columns, exclude_cols = prepare_classification_data(df, target_column)\n",
    "    \n",
    "    print(f'y labeled shape: {y_labeled.shape}')\n",
    "    print(f'x labeled shape: {X_labeled.shape}')\n",
    "    print(f'x unlabeled shape: {X_unlabeled.shape}')\n",
    "    \n",
    "    # Split labeled data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_labeled, y_labeled, test_size=0.2, random_state=42, stratify=y_labeled\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    model, y_pred, y_test_encoded, label_encoder = train_xgboost_classifier(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    print(f'y pred shape: {y_pred.shape}')\n",
    "    \n",
    "    # Evaluate\n",
    "    evaluate_model(y_test_encoded, y_pred, label_encoder)\n",
    "    \n",
    "    # Get feature importance\n",
    "    feature_importance = get_feature_importance(model, feature_columns)\n",
    "    \n",
    "    # Cross-validate\n",
    "    cv_scores = cross_validate_model(X_labeled, y_labeled)\n",
    "    \n",
    "    # Predict unlabeled\n",
    "    if len(X_unlabeled) > 0:\n",
    "        predictions, probabilities = predict_unlabeled_seizures(model, X_unlabeled, label_encoder)\n",
    "        print(f\"\\nPredicted {len(predictions)} unlabeled seizures\")\n",
    "    else:\n",
    "        predictions, probabilities = None, None\n",
    "    \n",
    "    return model, label_encoder, predictions, probabilities, feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6edbf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load functions\n",
    "def save_model(model, label_encoder, filepath_prefix):\n",
    "    \"\"\"\n",
    "    Save model and label encoder\n",
    "    \"\"\"\n",
    "    joblib.dump(model, f\"{filepath_prefix}_model.pkl\")\n",
    "    joblib.dump(label_encoder, f\"{filepath_prefix}_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath_prefix):\n",
    "    \"\"\"\n",
    "    Load model and label encoder\n",
    "    \"\"\"\n",
    "    model = joblib.load(f\"{filepath_prefix}_model.pkl\")\n",
    "    label_encoder = joblib.load(f\"{filepath_prefix}_encoder.pkl\")\n",
    "    return model, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84870a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_classifiers(df):\n",
    "    \"\"\"\n",
    "    Train classifiers for all three target variables\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for target in ['seizure_type', 'localization', 'lateralization']:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training classifier for: {target}\")\n",
    "        print('='*50)\n",
    "        \n",
    "        model, encoder, predictions, probabilities, feature_importance = build_seizure_classifier(df, target)\n",
    "        \n",
    "        results[target] = {\n",
    "            'model': model,\n",
    "            'encoder': encoder,\n",
    "            'predictions': predictions,\n",
    "            'probabilities': probabilities,\n",
    "            'feature_importance': feature_importance\n",
    "        }\n",
    "        \n",
    "        # Save model\n",
    "        save_model(model, encoder, f\"{target}_classifier\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4062ca",
   "metadata": {},
   "source": [
    "## Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2660d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets =[\n",
    "    'seizure_type', \n",
    "    'localization', \n",
    "    'lateralization'\n",
    "]\n",
    "processed_df = processed_df.with_columns(\n",
    "    pl.col(targets).cast(pl.Categorical)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f0581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['seizure_type'].n_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a7ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categoricals(df):\n",
    "    # Copy dataframe to avoid modifying original\n",
    "    encoded_df = df.clone()\n",
    "    \n",
    "    # Dictionary to store encoding mappings\n",
    "    encoding_mappings = {}\n",
    "    \n",
    "    # Process each column\n",
    "    for col in df.columns:\n",
    "        dtype = df[col].dtype\n",
    "        \n",
    "        # Check if column is string/object type\n",
    "        if dtype == pl.Utf8 or dtype == pl.Object:\n",
    "            # Get unique values and create mapping (starting from 1)\n",
    "            unique_vals = encoded_df[col].unique().drop_nulls().sort()\n",
    "            mapping = {val: i+1 for i, val in enumerate(unique_vals)}\n",
    "            encoding_mappings[col] = mapping\n",
    "            \n",
    "            # Apply the mapping directly\n",
    "            encoded_df = encoded_df.with_columns(\n",
    "                pl.col(col).replace(mapping).alias(col)\n",
    "            )\n",
    "    \n",
    "    return encoded_df, encoding_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85883292",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df, encoding_mappings = encode_categoricals(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'time_zero_crossings_std',\n",
    "    'de_delta_asymmetry_mean',\n",
    "    'ictal_wt_level5_entropy_std',\n",
    "    'pac_theta_high_gamma',\n",
    "    'de_theta_asymmetry_mean',\n",
    "    'ictal_wt_level3_entropy_std',\n",
    "    'permutation_entropy_std',\n",
    "    'ictal_time_hjorth_complexity_max',\n",
    "    'ictal_de_high_beta_asymmetry_mean',\n",
    "    'ictal_de_low_beta_asymmetry_mean',\n",
    "    'de_alpha_median',\n",
    "    'duration_seconds',\n",
    "    'time_mean_min',\n",
    "    'de_delta_mean',\n",
    "    'time_mean_mean',\n",
    "    'wt_level0_entropy_std',\n",
    "    'patient_id',\n",
    "    'seizure_type',\n",
    "    'localization',\n",
    "    'lateralization'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74df70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = encoded_df.select(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all classifiers\n",
    "results = train_all_classifiers(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e74f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access individual results\n",
    "seizure_type_model = results['seizure_type']['model']\n",
    "seizure_type_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0bcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seizure_type_predictions = results['seizure_type']['predictions']\n",
    "seizure_type_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "seizure_type_feature_importances = results['seizure_type']['feature_importance']\n",
    "seizure_type_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_feature_importances_to_df(feature_importances):\n",
    "    \"\"\"Convert list of (feature_name, importance_value) tuples to Polars DataFrame\"\"\"\n",
    "    feature_names = [item[0] for item in feature_importances]\n",
    "    importance_values = [float(item[1]) for item in feature_importances]\n",
    "    \n",
    "    return pl.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importance_values\n",
    "    })\n",
    "    \n",
    "seizure_type_feature_df = convert_feature_importances_to_df(seizure_type_feature_importances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
